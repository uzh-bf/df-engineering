---
title: Automated Grading
---

# Project Goal

A key requirement when performing any kind of exam correction is to guarantee a **valid, objective** and **fair** **grading process**. There is often some room for interpretation when grading, especially in **open-ended** exam questions, where students generate answers themselves (i.e., the solution space is much broader than with, e.g., single-choice questions). **Procedural fairness** – referring to the perception of correctability and consistency – is of importance in the design, conduction and correction process of any exam, and is at the core of our project.

Our primary goal is to evaluate whether and how the correction of exams could be supported with **automated tools and procedures**. (Semi-)automated correction of open-ended exam questions has the potential to reduce human subjective judgement, improve fairness for the students, as well as allow lecturers to grade in a more structured and efficient way.

# Resources

- The first version of a public knowledge base is available at https://publish.obsidian.md/automated-correction and open-sourced at https://github.com/uzh-bf/p8-automated-correction
- An updated knowledge base is #work-in-progress
- A platform that facilitates exam grading using #LLM and #AI is #work-in-progress
